---
title: "Systems"
order: 2
path: "/tools"
---


Two topics which appear to have nothing to do with each other. Programming Style & Your Brain. Programming style is the part of your program that the compiler ignores and some people think that because the compiler doesn't care,you shouldn't care, any style's good as another, it's just a matter of taste. I'm going to try to persuade you that that is not that case, that some styles are significantly better than others. 

And then, your brain. Your brain is that big wad of meat in your skull that you think with. And what possible connection could there be between these two things? Well, turns out there is a connection, a surprising and important one.

I'm going to be misrepresenting the work of Daniel Kahneman, the Nobel winning psychologist. Now, Nobel does not give a prize for psychology, so they gave him the award for economics, but he's not an economist. He found that one of the fundamental assumptions of economics doesn't hold, that is that in any transaction, a party can be expected to pursue their own best interest. Kahneman shows that this is not the case, if a party is a human being, because human beings do not think the way in fact, none of us think the way we think we think, and the more you study Kahneman, the more amazing it is that we  ever get anything done at all. So, Kanheman has a metaphor for human thought, based on the interactions of two systems, system two and system one. _System two_, which we can think of as the __head__, is the higher level one. It's analytic, it's algorithmic, it's where we do mathematics, and reasoning, and logic. It's a really sophisticated machine. 
It requires a tremendous amount of effort to use, and it is very slow. So we leave it turned off as much as possible. It's because that system is so slow
that we had to invent computers. System two is not capable of generating all of the numbers that society needed in order to do its social evolution, so we needed to come up with machines to do that processing for us. 

Then there's system one. _System one_, you can think of as your __gut__. It is intuitive, it's heuristic, it's associative. It is very, very fast. It requires no effort. And in fact, you cannot turn it off. It's on all the time. And the idea that we have these two systems is not new. We all have this intuitive sense that we've got these two systems. And sometimes you can even hear them. Sometimes if you're confused about something important, you can hear your head telling you one thing and your gut telling you something else. I mean, we've all experienced that. 

What Kahneman found was how the two systems are connected. It turns out system two gets its assumptions, its givens, its working set, from system one, and is not aware of that connection. System two think it's getting this stuff from the vault of deep truth, but it's not. It's getting it from system one. And system one, because it's an approximate system, sometimes gets things wrong. And if you have a logical system with false inputs, you can get false outputs. It turns out we do this all the time.


Let use an analogy from visual processing. __Visual processing__ is the opposite of computer graphics. It's where you take a signal from a camera and analyze all the pixels and try to determine what are all the objects on the scene and how are they all moving relative to each other and the camera. You need to be able to solve this problem in order to walk in the world. And it's a really, really difficult problem. But, we're all able to solve it, and in fact all the animals are able to solve it, and the reason we're able to do that is because we don't solve the general problem. General problem is hard. Instead we solve special problems which are much easier to solve, but which sometimes give the wrong answer. And we have techniques for revealing the ways in which we get this wrong. And we call them optical illusions.

So, this is an illusion designed by Edward Adelson of MIT. Here we've got a checkerboard with white squares and black squares.

![illusion](/images/greyillusion.png)

And two of the squares are labeled A and B. And it turns out, those two squares are exactly the same color. Some of you may be seeing that, you know, you may believ that I'm telling you that, but you're looking at that and one is clearly white and one is clearly black. But, in fact, they are both that color, they are both that shade of neutral gray.

![illusion](/images/illusion_II.jpg)

And, in fact, if I overlay my squar on top of the picture, if A and B were different colors, then you should see some break in continuity, right? You should see some edge forming and you don't.

Now, many of you may be seeing a gradient. Your brain is lying to you. There's not a gradient. It is that color, it is a solid colored square. You know the truth of this image and yet you still can't see it correctly.

It's because there's another part of your brain that Kahneman doesn't talk about which deals with inconsistency, which is a really important thing to have because if a computer system becomes inconsistent, there's a really good chance that it's going to fail. Right? It's just nah, boom. And biological systems can't afford to fail when they get confused.

So, instead we've got this system, which will reject information which is coming from the world through our senses if it contradicts our internal state. And that's why you cannot see this correctly because it is altering what you are seeing with your eyes in order to conform with your patterns of image processing. And it turns out, we do this all the time. It's not just in the visual system, it's in everything. And that's why we argue so much because we literally cannot hear what the other person is saying. The other person is saying something which contradicts us, then we will misinterpret what they're saying. It's not intentional, it's just part of what we're doing in order to resist inconsistency.

It turns out none of this was news to the advertising industry. They'd figured out a long time ago that they could design messages which would bypass the head that would go straight to the gut convincing us we have to buy things that we don't need. They've been doing this for a long long time. What Kahneman does is provide the theory which explains why that works. And I don't think anybody understood this better than the tobacco industry. 'Cause you look at tobacco. Okay, so how do you sell tobacco? What does tobacco do? It makes you smell bad, it turns your teeth yellow, it makes you sick, and then it kills you. So, how do you convince people? Yeah, let's buy some tobacco. And they do it by creating messages which are able to confuse System One. System One is easily confused about the difference between a slow death and good for you. 

That is the equipment that we have for writing computer programming or for writing computer programs. And programs are the most complicated things that humans make. There's nothing else in human experience which is composed of as many tiny little pieces which all have to go together perfectly that have to work in real-time with changing states and changing inputs in a dynamic situation. Nothing else comes anywhere close to the complexity that we have in software. And it's amazing that we're able to manage this, but it's really hard. When the first Van Neumann machine started coming online and it was discovered programming is really really difficult. You know, there was a lot of thinking that we need to figure out a way in order to make it easier. In fact, to make it unnecessary 'cause otherwise the computers are not much use to us. And so, that started research in artificial intelligence. And the goal of artificial intelligence originally was to figure out a way to have the computers write their own programs because it was just too hard to have humans writing them. A.I. has had a lot of amazing successes but, they have failed completely at their original mission that you cannot give a problem to a computer and ask it to write the program that solves that problem. If it were, then we would ask to computer, well, write a program that's better than you and keep doing that until they become our overlords. And that hasn't happened. Computers don't know how to write programs, so we write them. So, as a result of the failure of A.I., we are still writing programs by hand. So, the most important tool we have for doing programming is the programming language because one thing that computers are really good at is translating one formal language into another formal language.
And that's what programming languages do. They allow us to write at increasing higher levels of abstraction where we get more leverage, where we can create more work with less effort than the computer through the programming language, figures out how to convert it into a form the computer can execute. And so, programming languages are really really important. The thing that makes programming so extremely difficult is the requirement for perfection. Programs have to be absolutely perfect in every aspect, in every detail, for all possible inputs, for all possible states, for all time. And the contract we have with the computer is that if a program is not perfect in all of those ways, the computer has license to do the worst possible thing at the worst possible time, and it is not the computer's fault. Who's fault is it? It's your fault. Why did you give us a program which you knew wasn't perfect? So, you'd think, well okay, because of that requirement for perfection, we would never release a program to production until we know it's perfect. And we don't do that for two really good reasons: The first one is, we would never release a program to production. And eventually management would figure, "why are we paying these guys? "They never finish. "Let's figure out something else." But the second reason is much more insidious. And that is, we have no test for perfection. It may be that someone once created a complex program that actually was perfect. There's no way to know. There's no test for perfection. We have tests for imperfection, but no test for perfection. So, there's just no way to tell. Now, it's most likely that none of our programs are perfect.

So, what we do is we put our programs into production, hoping that we'll discover what's wrong with it and fix it before anyone else finds out, which is crazy. But, that is the state of the art, that is the best we have figured out how to do. So, we're doing this work with the brains of hunters and gatherers. And this is not a metaphor. Our brains have not evolved since the last Ice Age. And there was nothing in that experience to have prepared us for computer programming. Hunting and gathering required a completely different set of skills. So, it's kind of amazing that we're able to do this at all. It's sort of lucky, but there's nothing in our evolution which has prepared us for this. So, we're making use of everything we have in order to do this. So, programming obviously is making use of the head, of System Two, because that's where the algorithms live, that's where we do the analytical stuff, that's where we do the logic, and the state, and the dynamic stuff, all of that stuff. But, we don't understand how we do it. You have all figured it out, but not well enough that you can write down a list of instructions, this is how you write a computer program, you do these things, and hand it to someone else, and they can read it, and follow those steps, and then they can write programs. We can't do that. Somehow we have all figured it out, but not well enough that we can tell someone else how to do it. And that's why we can't tell the machines how to do it 'cause if we could tell another human how to do it, then could tell a machine how to do it. And we don't know. And much of what we are doing involves intuition because we're always making trade-offs. It's never clear what the best approach to solving a problem is going to be. And usually, we're trying to solve a problem with incomplete knowledge of what the solution is going to be, and so, we have to guess. And System Two is not good at guessing. System One loves to guess. System One will guess without knowing it's guessing. It's great at that. And, you know, so we look at a problem and we'll look at it top-down and bottom-up, and take a macro-view and a micro-view, we keep constantly shifting our point of view until eventually a program emerges. And we don't know how we do that. You know, System Two is obviously involved, but I think System One is involved there as well. That's part of the reason why we can't document it. Now, I have no evidence to support that argument, but my gut tells me it's true, so I believe it.